同样的，这里还是放上[原文参考](https://time.geekbang.org/column/article/40036)。

## 复杂度分析

我们需要的是一个不用具体的测试数据来测试，就可以此略的估计算法的执行效率的方法。

### 时间复杂度

假设所有代码在 CPU 上的执行时间都相同，那么所有代码的执行时间`T(n)`都与每行代码的执行次数成正比。

```go
func cal(n int) int {
    sum := 0
    i := 1
    j := 1
    for ; i < n; i++ {
        j = 1
        for ; j < n; j++ {
            sum = sum + i * j
        }
    }
    return sum
}
```

这段代码的执行总时间`T(n)`为`2n*n + 2n + 3`，大 O 公式为下：

```c
T(n) = O(f(n))
```

其中`n`表示数据规模，`f(n)`表示代码执行的总次数；`O`表示代码的执行时间`T(n)`与`f(n)`成正比。

但是，大 O 时间复杂度表示法实际上并不是具体的代码执行时间，而是表示**代码执行时间随着数据规模增长的变化趋势**，所以也叫做**渐进时间复杂度（asymptotic time complexity）**，简称时间复杂度。

因此当 n 取值很大的时候，公式中的低阶、系数、常量便无法再左右其增长趋势了，都可忽略，所以我们只记录一个最大量级即可。上示为：`T(n)=O(n*n)`。

**O(1)**：只要代码的执行时间不随着 n 的增大而增长，不管有几行代码那这就是 O(1)。

**O(logn)、O(nlogn)**，有如下代码：

```go
i := 1
for i <= n {
    i = i * 2
}
```

只要分析出了第三行代码的执行次数，就能得到整段代码的时间复杂度；先分析变量`i`的取值为 i 的一次方、二次方、三次直到`i 的 x 次方等于 n`，也就是说**次数 x 等于  log 以 i 为底的 n**。

```go
i ：= 1
for i <= n {
    i = i * 3
}
```

不管其低数是 2 还是 3，我们都可以将所有对数阶的时间复杂度记为 O(logn)。现在再来理解**O(nlogn)**就很容易了，当一段时间复杂度为 O(logn) 的代码在循环中执行了 n 遍，那总时间复杂度就是 O(nlogn) 了；归并、快排的时间复杂度都是它。

**O(m+n)、O(m*n)**：该种时间复杂度是由两个数据规模来决定的，我们事先无法评估 m 和 n 谁的数据规模更大，因此就不能简单地忽略掉任一个。

### 空间复杂度

类比时间复杂度，空间复杂度的全名是**渐进空间复杂度（asymptotic space complexity），表示的是算法的存储空间与数据规模增长的变化趋势。**

```go
func Print(n int) {
        i := 0
        a := make([]int, n)

        for ; i < n; i++ {
                a[i] = i * i
        }

        for i = n - 1; i >= 0; i-- {
                fmt.Println(a[i])
        }
}
```

上例代码中，我们申请的变量`i`的存储空间是常量阶的，与数据规模 n 无关便可忽略。仅在第三行申请了大小为 n 的整型数组，此外后续代码再为申请更多存储空间。因此空间复杂度为 O(n)。

我们常见的空间复杂度就是 O(1), O(n), O(n*n)，对数阶的平时也见不到。

### 理解部分

**最好、最坏情况时间复杂度**，分别是在最理想的情况下与在最糟糕的情况下执行这段代码的时间复杂度。好比是在要通过遍历一个数组而得到 key 直的索引后便返回时，它的可能出现在数组头部或是尾部。

而**平均情况时间复杂度**对应的是在大概率的非极端情况下的代码时间复杂度。如果将各种情况的概率也都考虑进去，那么平均时间复杂度的计算就变为了概率论中的**加权平均值**，也叫做**期望值**，所以平均时间复杂度的全称应该为**加权平均时间复杂度**或者**期望时间复杂度**。

不过，我们也只会在同一块代码在不同情况下的时间复杂度有量级上的差异时，才会区分以上三种复杂度。

**均摊时间复杂度**的应用场景更加有限：不同种的时间复杂度的出现频率非常有关系，而且还有着一定的前后时序关系，如一个 O(n) 操作后紧跟着 n-1 一个 O(1) 操作，循环往复。将耗时多的操作均摊到耗时少的 n-1 此操作上，也就是将这一组操作放在一起分析。



## 排序

| 冒泡、插入、选择 | O(n*n)   | 基于比较   |
| ---------------- | -------- | ---------- |
| 快排、归并       | O(nlogn) | 基于比较   |
| 桶、记数、基数   | O(n)     | 不基于比较 |

排序时的考虑因素：

- 最好情况、最坏情况、平均情况时间复杂度；
- 时间复杂度的系数、常数、低阶： 当在数据规模很小的时候，就需要把这些都考虑进去；
- 比较次数和交换次数：基于比较的排序算法会涉及元素的比较或者交换操作；
- 内存消耗：可以通过空间复杂度来衡量，原地排序算法就是特指空间复杂度为 O(1) 的排序算法；
- 排序算法的稳定性：如果待排序的序列中存在值相等的元素，经过排序之后相等元素之间的原有先后顺序不变；

### 冒泡排序 Bubble Sort

每次冒泡排序都会对相邻的两个元素进行比较，如果不满足大小关系就进行交换。一次冒泡排序至少会让一个元素移动至它应该在的位置，重复 n 次便完成了排序任务。

当然如果某次冒泡操作中没有进行交换，就说明数据已经到达了完全有序的状态，表现为下面的`flag`变量。

```go
func BubbleSort(a []int) {

	n := len(a)

	if n < 2 {
		return
	}

	flag := true
	for i := 0; i < n && flag; i++ {
		for j := 0; j < n-i-1; j++ {
			if a[j] > a[j+1] {
				a[j], a[j+1] = a[j+1], a[j]
				flag = true
			}
		}
	}
}
```

真个冒泡过程只有交换数据以及常量级的临时临时空间，一次空间复杂度为 O(1) 是原地排序算法；当存在相邻的相等元素时，我们未对其做出交换所以冒泡是稳定的排序算法。

### 插入排序 Insertion Sort

先将数组中的数据分为两个区间，**已排序区间**和**未排序区间**。并且将首元素归入已排序区间，插入算法就是一直在从未排序区间中取出一个元素并将其插入至已排序区间的合适位置，以保证已排序区间的数据一直有序。插入时会涉及到数据的搬移操作，重复这个过程直至未排序区间为空。

```go
func InsertionSort(a []int) {
	n := len(a)

	if n < 2 {
		return
	}
	// 假设元素 0 处于已排序区间中
	for i := 1; i < n; i++ {
		value := a[i]
		j := i - 1
		for ; j >= 0; j-- {
			if a[j] > value {
				a[j+1] = a[j]
			} else {
				break
			}
		}
		// 跳出循环时便说明 a[j] 不够大
		// 即 value 值应该插入在 a[j] 后
		a[j+1] = value
	}
}
```

插入排序也不需要额外的存储空间，所以空间复杂度为 O(1) 也是原地排序算法；

仔细观察插入与冒泡中的数据移动操作，冒泡的明显要比插入的要复杂元素移动次数要多，当追求极致性能的时候便会选择插入排序。

给出一个测试文件`Sort_test.go`：

```go
package main

import "testing"
import "math/rand"

func TestInsertionSort(t *testing.T) {

	var num [10][10]int

	for i := 0; i < 10; i++ {
		for j := 0; j < 10; j++ {
			num[i][j] = rand.Intn(99)
		}
	}

	for _, vv := range num {
        // 将数组转为切片
		v := vv[:]
		InsertionSort(v)
		t.Log(v)
	}
}
```

### 选择排序 Selection Sort

选择排序也区分已排序区间与未排序区间，不过选择排序每次会从未排序区间中找到最小值，放至已排序区间的末尾。当假设最开始已排序区间元素数量为 0 时，那就是将最小值与第一个元素直接交换。

```go
func SelectionSort(a []int) {
	n := len(a)

	if n < 2 {
		return
	}

	for i := 0; i < n; i++ {
		minIndex := i
        // 从未排序区间的第一个元素开始找
		for j := i + 1; j < n; j++ {
			if a[j] < a[minIndex] {
				minIndex = j
			}
		}
		a[i], a[minIndex] = a[minIndex], a[i]
	}
}
```

选择排序也是原地排序，但是因为他会将最小值元素与考前的元素进行交换而破换了原数据的稳定性；正是因如此，选择排序才稍逊色与冒泡与插入了。



















